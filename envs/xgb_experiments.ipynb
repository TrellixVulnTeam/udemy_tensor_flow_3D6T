{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "- Creating dataset \n",
    "    - Frequency and severity response \n",
    "    - Groups to represent policy number \n",
    "    - Extra (invisible) features to represent cytora external features for building lift model \n",
    "- Build xgb model \n",
    "    - Evaluate on mse, loglikelihood, feature importance with graphviz \n",
    "- Cross validated predicitions \n",
    "    - Evaluate on same metrics \n",
    "- Build lift model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import scipy as sc\n",
    "\n",
    "from sklearn.cross_validation import cross_val_predict as cvp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating dataset \n",
    "\n",
    "Features \n",
    "- building declared value gamma \n",
    "- \n",
    "\n",
    "Response \n",
    "- Increasing error dependent of mu \n",
    "- Poisson frequency \n",
    "- Gamma severity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bdv</th>\n",
       "      <th>building_height</th>\n",
       "      <th>years_old</th>\n",
       "      <th>factory</th>\n",
       "      <th>other</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>expected_claim_count</th>\n",
       "      <th>claim_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.296961e+06</td>\n",
       "      <td>6.644808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12064</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.671498e+07</td>\n",
       "      <td>7.743655</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0.113439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.977065e+06</td>\n",
       "      <td>22.414727</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17753</td>\n",
       "      <td>0.025092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.227026e+06</td>\n",
       "      <td>7.736910</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14972</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.144710e+07</td>\n",
       "      <td>33.959818</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14067</td>\n",
       "      <td>0.250523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bdv  building_height  years_old  factory  other  restaurant  \\\n",
       "0  6.296961e+06         6.644808          0        0      1           0   \n",
       "1  1.671498e+07         7.743655          6        1      0           0   \n",
       "2  4.977065e+06        22.414727          6        1      0           0   \n",
       "3  7.227026e+06         7.736910         14        1      0           0   \n",
       "4  1.144710e+07        33.959818          3        0      0           1   \n",
       "\n",
       "   policy_number  expected_claim_count  claim_count  \n",
       "0          12064              0.000558            0  \n",
       "1            106              0.113439            1  \n",
       "2          17753              0.025092            0  \n",
       "3          14972              0.013730            0  \n",
       "4          14067              0.250523            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 100000\n",
    "# with 1000000 it takes very long: [20150]\teval-poisson-nloglik:0.182184\ttrain-poisson-nloglik:0.166313\n",
    "\n",
    "\n",
    "def trade(x):\n",
    "    if x == 1:\n",
    "        return 'restaurant'\n",
    "    if x == 2:\n",
    "        return 'factory'\n",
    "    return 'other'\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'bdv': sc.random.gamma(2,6000000,n),\n",
    "    'years_old': sc.random.randint(0,20,n),\n",
    "    'building_height': sc.random.gamma(1,20,n),\n",
    "    'trade': pd.Series(sc.random.randint(0,3,n)).apply(trade) \n",
    "})\n",
    "\n",
    "df[list(pd.get_dummies(df['trade']))] = pd.get_dummies(df['trade'])\n",
    "df.drop('trade', axis=1,inplace=True)\n",
    "\n",
    "df['policy_number'] = sc.random.randint(0, np.round(n/5), n)\n",
    "\n",
    "\n",
    "df['expected_claim_count'] = 0.1\n",
    "df['expected_claim_count'] = df['expected_claim_count'] * (df['bdv'] / 6000000)**3\n",
    "df['expected_claim_count'] = 0.7 * df['expected_claim_count'] * (df['building_height'] / 80)**2\n",
    "df['expected_claim_count'] = df['expected_claim_count'] + df['expected_claim_count'] * df['factory'] * 4\n",
    "df['expected_claim_count'] = df['expected_claim_count'] + df['expected_claim_count'] * df['restaurant'] * 1.2\n",
    "df['expected_claim_count'] = df['expected_claim_count'] * (1 + df['years_old'] / 10)\n",
    "\n",
    "\n",
    "\n",
    "# df['expected_claim_amount'] = 0.2\n",
    "# df['expected_claim_amount'] = df['expected_claim_amount'] * (df['building_height'] / 80)\n",
    "# df['expected_claim_amount'] = df['expected_claim_amount'] + df['expected_claim_count'] * df['factory'] * 100\n",
    "# df['expected_claim_amount'] = df['expected_claim_amount'] + df['expected_claim_count'] * df['restaurant'] * 1.4\n",
    "# df['expected_claim_amount'] = df['expected_claim_amount'] * (1 + df['years_old'] / 20)\n",
    "\n",
    "\n",
    "# print('amount>bdv:', sum(df['expected_claim_amount'] > 1) / len(df))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['claim_count'] = df['expected_claim_count'].apply(lambda x: sc.random.poisson(x))\n",
    "# df['incurred'] = df['expected_claim_amount'].apply(lambda x: sc.random.gamma(x))\n",
    "\n",
    "\n",
    "# print('incurred>bdv:', sum(df['incurred'] > 1) / len(df))\n",
    "\n",
    "\n",
    "# df['incurred'] = df['expected_claim_amount'].clip(0,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "# display(df[['expected_claim_amount']].describe())\n",
    "\n",
    "# df['expected_claim_amount'].plot('hist', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bdv</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.198925e+07</td>\n",
       "      <td>8.470553e+06</td>\n",
       "      <td>2.712660e+04</td>\n",
       "      <td>5.781876e+06</td>\n",
       "      <td>1.006788e+07</td>\n",
       "      <td>1.613585e+07</td>\n",
       "      <td>1.075599e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_height</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.993280e+01</td>\n",
       "      <td>1.997459e+01</td>\n",
       "      <td>2.582532e-04</td>\n",
       "      <td>5.710857e+00</td>\n",
       "      <td>1.378784e+01</td>\n",
       "      <td>2.765624e+01</td>\n",
       "      <td>2.693264e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_old</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>9.489280e+00</td>\n",
       "      <td>5.778311e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>factory</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.342300e-01</td>\n",
       "      <td>4.717229e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.356300e-01</td>\n",
       "      <td>4.722126e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restaurant</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.301400e-01</td>\n",
       "      <td>4.702657e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_number</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>9.983802e+03</td>\n",
       "      <td>5.775938e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.969000e+03</td>\n",
       "      <td>9.950000e+03</td>\n",
       "      <td>1.498300e+04</td>\n",
       "      <td>1.999900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_claim_count</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.115340e+00</td>\n",
       "      <td>8.262140e+00</td>\n",
       "      <td>1.221415e-12</td>\n",
       "      <td>2.398230e-03</td>\n",
       "      <td>2.887462e-02</td>\n",
       "      <td>2.472339e-01</td>\n",
       "      <td>6.290547e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim_count</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.117820e+00</td>\n",
       "      <td>8.337708e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.330000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count          mean           std           min  \\\n",
       "bdv                   100000.0  1.198925e+07  8.470553e+06  2.712660e+04   \n",
       "building_height       100000.0  1.993280e+01  1.997459e+01  2.582532e-04   \n",
       "years_old             100000.0  9.489280e+00  5.778311e+00  0.000000e+00   \n",
       "factory               100000.0  3.342300e-01  4.717229e-01  0.000000e+00   \n",
       "other                 100000.0  3.356300e-01  4.722126e-01  0.000000e+00   \n",
       "restaurant            100000.0  3.301400e-01  4.702657e-01  0.000000e+00   \n",
       "policy_number         100000.0  9.983802e+03  5.775938e+03  0.000000e+00   \n",
       "expected_claim_count  100000.0  1.115340e+00  8.262140e+00  1.221415e-12   \n",
       "claim_count           100000.0  1.117820e+00  8.337708e+00  0.000000e+00   \n",
       "\n",
       "                               25%           50%           75%           max  \n",
       "bdv                   5.781876e+06  1.006788e+07  1.613585e+07  1.075599e+08  \n",
       "building_height       5.710857e+00  1.378784e+01  2.765624e+01  2.693264e+02  \n",
       "years_old             4.000000e+00  9.000000e+00  1.500000e+01  1.900000e+01  \n",
       "factory               0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  \n",
       "other                 0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  \n",
       "restaurant            0.000000e+00  0.000000e+00  1.000000e+00  1.000000e+00  \n",
       "policy_number         4.969000e+03  9.950000e+03  1.498300e+04  1.999900e+04  \n",
       "expected_claim_count  2.398230e-03  2.887462e-02  2.472339e-01  6.290547e+02  \n",
       "claim_count           0.000000e+00  0.000000e+00  0.000000e+00  6.330000e+02  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'bdv',\n",
    "    'building_height',\n",
    "    'years_old',\n",
    "    'factory',\n",
    "    'other',\n",
    "    'restaurant',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_kfold = sk.model_selection.GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[features]#.values\n",
    "y = df['claim_count']#.values\n",
    "groups = df['policy_number']#.values\n",
    "\n",
    "\n",
    "group_kfold.get_n_splits(\n",
    "    X, \n",
    "    y,\n",
    "    groups\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 6)\n",
      "(20000, 6)\n",
      "(80000,)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 2, \n",
    "    'eta': 0.2, \n",
    "    'silent': True, \n",
    "    \"objective\": \"count:poisson\",\n",
    "    \"eval_metric\": \"poisson-nloglik\",\n",
    "    'verbose_eval': 10,\n",
    "#     'early_stopping_rounds': 50\n",
    "}\n",
    "\n",
    "early_stopping_rounds = 50\n",
    "num_round = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-poisson-nloglik:2.26907e+09\teval-poisson-nloglik:2.36772e+09\n",
      "Multiple eval metrics have been passed: 'eval-poisson-nloglik' will be used for early stopping.\n",
      "\n",
      "Will train until eval-poisson-nloglik hasn't improved in 50 rounds.\n",
      "[50]\ttrain-poisson-nloglik:1.58196e+07\teval-poisson-nloglik:1.65074e+07\n",
      "[100]\ttrain-poisson-nloglik:110291\teval-poisson-nloglik:115086\n",
      "[150]\ttrain-poisson-nloglik:768.899\teval-poisson-nloglik:802.371\n",
      "[200]\ttrain-poisson-nloglik:5.81109\teval-poisson-nloglik:6.04809\n",
      "[250]\ttrain-poisson-nloglik:0.790669\teval-poisson-nloglik:0.765859\n",
      "[300]\ttrain-poisson-nloglik:0.688246\teval-poisson-nloglik:0.664167\n",
      "[350]\ttrain-poisson-nloglik:0.621169\teval-poisson-nloglik:0.599549\n",
      "[400]\ttrain-poisson-nloglik:0.588293\teval-poisson-nloglik:0.570431\n",
      "[450]\ttrain-poisson-nloglik:0.556968\teval-poisson-nloglik:0.542077\n",
      "[500]\ttrain-poisson-nloglik:0.534888\teval-poisson-nloglik:0.523523\n",
      "[550]\ttrain-poisson-nloglik:0.519755\teval-poisson-nloglik:0.511984\n",
      "[600]\ttrain-poisson-nloglik:0.511793\teval-poisson-nloglik:0.505695\n",
      "[650]\ttrain-poisson-nloglik:0.503402\teval-poisson-nloglik:0.499112\n",
      "[700]\ttrain-poisson-nloglik:0.498568\teval-poisson-nloglik:0.496168\n",
      "[750]\ttrain-poisson-nloglik:0.494755\teval-poisson-nloglik:0.49287\n",
      "[800]\ttrain-poisson-nloglik:0.491674\teval-poisson-nloglik:0.4901\n",
      "[850]\ttrain-poisson-nloglik:0.488477\teval-poisson-nloglik:0.488979\n",
      "[900]\ttrain-poisson-nloglik:0.485558\teval-poisson-nloglik:0.488727\n",
      "[950]\ttrain-poisson-nloglik:0.483259\teval-poisson-nloglik:0.487775\n",
      "[1000]\ttrain-poisson-nloglik:0.481456\teval-poisson-nloglik:0.48684\n",
      "[1050]\ttrain-poisson-nloglik:0.479796\teval-poisson-nloglik:0.486254\n",
      "[1100]\ttrain-poisson-nloglik:0.477484\teval-poisson-nloglik:0.485277\n",
      "[1150]\ttrain-poisson-nloglik:0.475993\teval-poisson-nloglik:0.484692\n",
      "[1200]\ttrain-poisson-nloglik:0.474093\teval-poisson-nloglik:0.484008\n",
      "[1250]\ttrain-poisson-nloglik:0.472903\teval-poisson-nloglik:0.483413\n",
      "[1300]\ttrain-poisson-nloglik:0.47156\teval-poisson-nloglik:0.48266\n",
      "[1350]\ttrain-poisson-nloglik:0.470469\teval-poisson-nloglik:0.482335\n",
      "[1400]\ttrain-poisson-nloglik:0.469756\teval-poisson-nloglik:0.482036\n",
      "[1450]\ttrain-poisson-nloglik:0.467916\teval-poisson-nloglik:0.481637\n",
      "[1500]\ttrain-poisson-nloglik:0.467066\teval-poisson-nloglik:0.481317\n",
      "[1550]\ttrain-poisson-nloglik:0.465932\teval-poisson-nloglik:0.481218\n",
      "[1600]\ttrain-poisson-nloglik:0.464771\teval-poisson-nloglik:0.480929\n",
      "[1650]\ttrain-poisson-nloglik:0.464482\teval-poisson-nloglik:0.480809\n",
      "[1700]\ttrain-poisson-nloglik:0.464081\teval-poisson-nloglik:0.480774\n",
      "[1750]\ttrain-poisson-nloglik:0.463448\teval-poisson-nloglik:0.480501\n",
      "[1800]\ttrain-poisson-nloglik:0.462916\teval-poisson-nloglik:0.480292\n",
      "[1850]\ttrain-poisson-nloglik:0.462473\teval-poisson-nloglik:0.480073\n",
      "[1900]\ttrain-poisson-nloglik:0.461971\teval-poisson-nloglik:0.479845\n",
      "Stopping. Best iteration:\n",
      "[1883]\ttrain-poisson-nloglik:0.462057\teval-poisson-nloglik:0.479818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evallist = [(dtrain, 'train') , (dtest, 'eval')]\n",
    "bst = xgb.train(\n",
    "    param, \n",
    "    dtrain, \n",
    "    num_round, \n",
    "    evallist, \n",
    "    early_stopping_rounds=early_stopping_rounds, \n",
    "    verbose_eval=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.000000e+04\n",
       "mean     1.102054e+00\n",
       "std      8.303184e+00\n",
       "min      7.253622e-07\n",
       "25%      2.110188e-03\n",
       "50%      2.862757e-02\n",
       "75%      2.535395e-01\n",
       "max      4.129277e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3f5d912e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(pred).plot('hist', bins=50)\n",
    "pd.Series(pred).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5867102546496872"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"555pt\" height=\"502pt\"\n",
       " viewBox=\"0.00 0.00 555.00 502.17\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 498.168)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-498.168 551,-498.168 551,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"290\" cy=\"-429.824\" rx=\"64.189\" ry=\"64.189\"/>\n",
       "<text text-anchor=\"middle\" x=\"290\" y=\"-426.124\" font-family=\"Times,serif\" font-size=\"14.00\">bdv&lt;32898518</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"149\" cy=\"-200.74\" rx=\"113.98\" ry=\"113.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"149\" y=\"-197.04\" font-family=\"Times,serif\" font-size=\"14.00\">building_height&lt;65.1123581</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M256.406,-374.72C243.711,-354.274 228.791,-330.246 214.179,-306.712\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"217.062,-304.721 208.814,-298.072 211.115,-308.414 217.062,-304.721\"/>\n",
       "<text text-anchor=\"middle\" x=\"271.5\" y=\"-336.28\" font-family=\"Times,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"394\" cy=\"-200.74\" rx=\"113.98\" ry=\"113.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"394\" y=\"-197.04\" font-family=\"Times,serif\" font-size=\"14.00\">building_height&lt;71.5647507</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M316.513,-370.934C324.55,-353.385 333.666,-333.48 342.751,-313.641\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"345.938,-315.089 346.92,-304.54 339.574,-312.174 345.938,-315.089\"/>\n",
       "<text text-anchor=\"middle\" x=\"339\" y=\"-336.28\" font-family=\"Times,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"134,-36 0,-36 0,-0 134,-0 134,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"67\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">leaf=&#45;0.00677321712</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M102.37,-96.9614C93.724,-77.9035 85.418,-59.596 79.0303,-45.5165\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"82.0596,-43.722 74.7406,-36.0614 75.6849,-46.6141 82.0596,-43.722\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"262,-36 152,-36 152,-0 262,-0 262,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">leaf=1.35814488</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M183.493,-92.2533C189.021,-75.0263 194.273,-58.6607 198.404,-45.7855\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"201.739,-46.8497 201.462,-36.2585 195.073,-44.7107 201.739,-46.8497\"/>\n",
       "<text text-anchor=\"middle\" x=\"202\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"419,-36 309,-36 309,-0 419,-0 419,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">leaf=2.01877689</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M375.513,-88.3619C372.91,-72.6774 370.455,-57.8868 368.486,-46.0252\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"371.914,-45.3056 366.824,-36.0137 365.009,-46.4519 371.914,-45.3056\"/>\n",
       "<text text-anchor=\"middle\" x=\"406.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"547,-36 437,-36 437,-0 547,-0 547,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"492\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">leaf=29.2914581</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M447.874,-100.381C458.965,-79.9257 469.72,-60.0904 477.835,-45.1238\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"481.074,-46.4933 482.764,-36.0341 474.92,-43.1567 481.074,-46.4933\"/>\n",
       "<text text-anchor=\"middle\" x=\"477\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fb3f5c49e80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.to_graphviz(bst, num_trees=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb3f5c64f28>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3f5d91588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validated predictions \n",
    "\n",
    "Take-aways:\n",
    "- Pete built cv predictions because this is not supported by cv functionality in xgboost api?\n",
    "    - only output is a pandas dataframe with cross validated performance \n",
    "    - doesn't create model instance with predict option \n",
    "- Pete just copied it and added the model_cv through CVPack and model_cv\n",
    "- This differs to the default xgboost.cv function in the following key ways:\n",
    "    - cv fold design matrices can be pre-computed to avoid repeating this time\n",
    "      consuming step every time cv() is called\n",
    "    - the CVPack objects are returned (which include the boosters for each\n",
    "      fold), allowing the cross-validated models to be used for prediction\n",
    "    - cv fold creation functionality dropped (as they should be pre-computed)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-poisson-nloglik:3.74603e+07+2.64037e+07\ttest-poisson-nloglik:4.28139e+07+3.01937e+07\n",
      "[50]\ttrain-poisson-nloglik:261166+184082\ttest-poisson-nloglik:398696+313246\n",
      "[100]\ttrain-poisson-nloglik:1820.39+1283.24\ttest-poisson-nloglik:2779.34+2183.62\n",
      "[150]\ttrain-poisson-nloglik:13.0037+8.66658\ttest-poisson-nloglik:19.701+15.0637\n",
      "[200]\ttrain-poisson-nloglik:0.764747+0.147234\ttest-poisson-nloglik:0.95053+0.368252\n",
      "[250]\ttrain-poisson-nloglik:0.65426+0.116838\ttest-poisson-nloglik:0.790589+0.280088\n",
      "[300]\ttrain-poisson-nloglik:0.589547+0.070015\ttest-poisson-nloglik:0.687559+0.180865\n",
      "[350]\ttrain-poisson-nloglik:0.550226+0.0414191\ttest-poisson-nloglik:0.629144+0.125205\n",
      "[400]\ttrain-poisson-nloglik:0.526795+0.0267183\ttest-poisson-nloglik:0.592965+0.0903845\n",
      "[450]\ttrain-poisson-nloglik:0.514233+0.0230298\ttest-poisson-nloglik:0.576708+0.081113\n",
      "[500]\ttrain-poisson-nloglik:0.506068+0.0199514\ttest-poisson-nloglik:0.566862+0.075905\n",
      "[550]\ttrain-poisson-nloglik:0.498288+0.0171224\ttest-poisson-nloglik:0.560562+0.0735735\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-poisson-nloglik-mean</th>\n",
       "      <th>test-poisson-nloglik-std</th>\n",
       "      <th>train-poisson-nloglik-mean</th>\n",
       "      <th>train-poisson-nloglik-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.281394e+07</td>\n",
       "      <td>3.019373e+07</td>\n",
       "      <td>3.746034e+07</td>\n",
       "      <td>2.640373e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.858025e+07</td>\n",
       "      <td>3.700107e+07</td>\n",
       "      <td>3.391865e+07</td>\n",
       "      <td>2.390739e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.596821e+07</td>\n",
       "      <td>3.576466e+07</td>\n",
       "      <td>3.071182e+07</td>\n",
       "      <td>2.164707e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.162216e+07</td>\n",
       "      <td>3.238330e+07</td>\n",
       "      <td>2.780817e+07</td>\n",
       "      <td>1.960045e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.768699e+07</td>\n",
       "      <td>2.932162e+07</td>\n",
       "      <td>2.517905e+07</td>\n",
       "      <td>1.774733e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.412388e+07</td>\n",
       "      <td>2.654941e+07</td>\n",
       "      <td>2.279850e+07</td>\n",
       "      <td>1.606941e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.089765e+07</td>\n",
       "      <td>2.403930e+07</td>\n",
       "      <td>2.064302e+07</td>\n",
       "      <td>1.455013e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.797643e+07</td>\n",
       "      <td>2.176651e+07</td>\n",
       "      <td>1.869133e+07</td>\n",
       "      <td>1.317449e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.564400e+07</td>\n",
       "      <td>2.007313e+07</td>\n",
       "      <td>1.692416e+07</td>\n",
       "      <td>1.192891e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.321949e+07</td>\n",
       "      <td>1.817532e+07</td>\n",
       "      <td>1.532407e+07</td>\n",
       "      <td>1.080109e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.102420e+07</td>\n",
       "      <td>1.645693e+07</td>\n",
       "      <td>1.387526e+07</td>\n",
       "      <td>9.779905e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.903647e+07</td>\n",
       "      <td>1.490101e+07</td>\n",
       "      <td>1.256342e+07</td>\n",
       "      <td>8.855265e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.723667e+07</td>\n",
       "      <td>1.349220e+07</td>\n",
       "      <td>1.137561e+07</td>\n",
       "      <td>8.018045e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.567506e+07</td>\n",
       "      <td>1.229637e+07</td>\n",
       "      <td>1.030011e+07</td>\n",
       "      <td>7.259981e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.419306e+07</td>\n",
       "      <td>1.113381e+07</td>\n",
       "      <td>9.326286e+06</td>\n",
       "      <td>6.573587e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.285118e+07</td>\n",
       "      <td>1.008117e+07</td>\n",
       "      <td>8.444533e+06</td>\n",
       "      <td>5.952088e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.163617e+07</td>\n",
       "      <td>9.128042e+06</td>\n",
       "      <td>7.646146e+06</td>\n",
       "      <td>5.389348e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.056900e+07</td>\n",
       "      <td>8.303799e+06</td>\n",
       "      <td>6.923242e+06</td>\n",
       "      <td>4.879813e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.569754e+06</td>\n",
       "      <td>7.518718e+06</td>\n",
       "      <td>6.268685e+06</td>\n",
       "      <td>4.418452e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.664983e+06</td>\n",
       "      <td>6.807862e+06</td>\n",
       "      <td>5.676012e+06</td>\n",
       "      <td>4.000710e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.845753e+06</td>\n",
       "      <td>6.164213e+06</td>\n",
       "      <td>5.139375e+06</td>\n",
       "      <td>3.622463e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.103977e+06</td>\n",
       "      <td>5.581419e+06</td>\n",
       "      <td>4.653473e+06</td>\n",
       "      <td>3.279978e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.432333e+06</td>\n",
       "      <td>5.053724e+06</td>\n",
       "      <td>4.213511e+06</td>\n",
       "      <td>2.969873e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.824188e+06</td>\n",
       "      <td>4.575920e+06</td>\n",
       "      <td>3.815145e+06</td>\n",
       "      <td>2.689087e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.273541e+06</td>\n",
       "      <td>4.143290e+06</td>\n",
       "      <td>3.454443e+06</td>\n",
       "      <td>2.434847e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.774955e+06</td>\n",
       "      <td>3.751563e+06</td>\n",
       "      <td>3.127842e+06</td>\n",
       "      <td>2.204645e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.323507e+06</td>\n",
       "      <td>3.396872e+06</td>\n",
       "      <td>2.832121e+06</td>\n",
       "      <td>1.996207e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.914742e+06</td>\n",
       "      <td>3.075715e+06</td>\n",
       "      <td>2.564358e+06</td>\n",
       "      <td>1.807476e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.544623e+06</td>\n",
       "      <td>2.784922e+06</td>\n",
       "      <td>2.321911e+06</td>\n",
       "      <td>1.636588e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.209497e+06</td>\n",
       "      <td>2.521622e+06</td>\n",
       "      <td>2.102386e+06</td>\n",
       "      <td>1.481857e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>5.624880e-01</td>\n",
       "      <td>7.365388e-02</td>\n",
       "      <td>5.011030e-01</td>\n",
       "      <td>1.744468e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>5.624817e-01</td>\n",
       "      <td>7.381722e-02</td>\n",
       "      <td>5.008190e-01</td>\n",
       "      <td>1.718576e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>5.623023e-01</td>\n",
       "      <td>7.392066e-02</td>\n",
       "      <td>5.006560e-01</td>\n",
       "      <td>1.723979e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>5.621907e-01</td>\n",
       "      <td>7.392944e-02</td>\n",
       "      <td>5.005343e-01</td>\n",
       "      <td>1.724762e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>5.621227e-01</td>\n",
       "      <td>7.394193e-02</td>\n",
       "      <td>5.003750e-01</td>\n",
       "      <td>1.716084e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>5.616730e-01</td>\n",
       "      <td>7.357218e-02</td>\n",
       "      <td>5.001563e-01</td>\n",
       "      <td>1.705210e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>5.616133e-01</td>\n",
       "      <td>7.363118e-02</td>\n",
       "      <td>5.000843e-01</td>\n",
       "      <td>1.704224e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>5.615703e-01</td>\n",
       "      <td>7.372491e-02</td>\n",
       "      <td>4.999247e-01</td>\n",
       "      <td>1.700401e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>5.613463e-01</td>\n",
       "      <td>7.361773e-02</td>\n",
       "      <td>4.997507e-01</td>\n",
       "      <td>1.688695e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>5.611210e-01</td>\n",
       "      <td>7.340459e-02</td>\n",
       "      <td>4.996430e-01</td>\n",
       "      <td>1.688866e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>5.610567e-01</td>\n",
       "      <td>7.342808e-02</td>\n",
       "      <td>4.995763e-01</td>\n",
       "      <td>1.688297e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>5.609513e-01</td>\n",
       "      <td>7.344376e-02</td>\n",
       "      <td>4.994387e-01</td>\n",
       "      <td>1.693046e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>5.609023e-01</td>\n",
       "      <td>7.342074e-02</td>\n",
       "      <td>4.991917e-01</td>\n",
       "      <td>1.709854e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>5.606613e-01</td>\n",
       "      <td>7.324163e-02</td>\n",
       "      <td>4.990880e-01</td>\n",
       "      <td>1.710685e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>5.608900e-01</td>\n",
       "      <td>7.364124e-02</td>\n",
       "      <td>4.988363e-01</td>\n",
       "      <td>1.710614e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>5.608207e-01</td>\n",
       "      <td>7.361660e-02</td>\n",
       "      <td>4.987203e-01</td>\n",
       "      <td>1.710568e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>5.606840e-01</td>\n",
       "      <td>7.368200e-02</td>\n",
       "      <td>4.986163e-01</td>\n",
       "      <td>1.715112e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>5.606313e-01</td>\n",
       "      <td>7.356806e-02</td>\n",
       "      <td>4.984620e-01</td>\n",
       "      <td>1.715163e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>5.605773e-01</td>\n",
       "      <td>7.357573e-02</td>\n",
       "      <td>4.983637e-01</td>\n",
       "      <td>1.711110e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>5.605623e-01</td>\n",
       "      <td>7.357351e-02</td>\n",
       "      <td>4.982877e-01</td>\n",
       "      <td>1.712240e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>5.604447e-01</td>\n",
       "      <td>7.365093e-02</td>\n",
       "      <td>4.981243e-01</td>\n",
       "      <td>1.719623e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>5.603207e-01</td>\n",
       "      <td>7.362665e-02</td>\n",
       "      <td>4.980277e-01</td>\n",
       "      <td>1.718641e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>5.599213e-01</td>\n",
       "      <td>7.320639e-02</td>\n",
       "      <td>4.979503e-01</td>\n",
       "      <td>1.718968e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>5.598857e-01</td>\n",
       "      <td>7.327042e-02</td>\n",
       "      <td>4.978850e-01</td>\n",
       "      <td>1.720929e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>5.596933e-01</td>\n",
       "      <td>7.308288e-02</td>\n",
       "      <td>4.978277e-01</td>\n",
       "      <td>1.719675e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>5.596553e-01</td>\n",
       "      <td>7.310459e-02</td>\n",
       "      <td>4.976780e-01</td>\n",
       "      <td>1.707933e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>5.595150e-01</td>\n",
       "      <td>7.297383e-02</td>\n",
       "      <td>4.975470e-01</td>\n",
       "      <td>1.695250e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>5.594050e-01</td>\n",
       "      <td>7.289210e-02</td>\n",
       "      <td>4.974800e-01</td>\n",
       "      <td>1.688523e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>5.590237e-01</td>\n",
       "      <td>7.235586e-02</td>\n",
       "      <td>4.973800e-01</td>\n",
       "      <td>1.675872e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>5.587077e-01</td>\n",
       "      <td>7.197753e-02</td>\n",
       "      <td>4.972290e-01</td>\n",
       "      <td>1.665618e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-poisson-nloglik-mean  test-poisson-nloglik-std  \\\n",
       "0                 4.281394e+07              3.019373e+07   \n",
       "1                 4.858025e+07              3.700107e+07   \n",
       "2                 4.596821e+07              3.576466e+07   \n",
       "3                 4.162216e+07              3.238330e+07   \n",
       "4                 3.768699e+07              2.932162e+07   \n",
       "5                 3.412388e+07              2.654941e+07   \n",
       "6                 3.089765e+07              2.403930e+07   \n",
       "7                 2.797643e+07              2.176651e+07   \n",
       "8                 2.564400e+07              2.007313e+07   \n",
       "9                 2.321949e+07              1.817532e+07   \n",
       "10                2.102420e+07              1.645693e+07   \n",
       "11                1.903647e+07              1.490101e+07   \n",
       "12                1.723667e+07              1.349220e+07   \n",
       "13                1.567506e+07              1.229637e+07   \n",
       "14                1.419306e+07              1.113381e+07   \n",
       "15                1.285118e+07              1.008117e+07   \n",
       "16                1.163617e+07              9.128042e+06   \n",
       "17                1.056900e+07              8.303799e+06   \n",
       "18                9.569754e+06              7.518718e+06   \n",
       "19                8.664983e+06              6.807862e+06   \n",
       "20                7.845753e+06              6.164213e+06   \n",
       "21                7.103977e+06              5.581419e+06   \n",
       "22                6.432333e+06              5.053724e+06   \n",
       "23                5.824188e+06              4.575920e+06   \n",
       "24                5.273541e+06              4.143290e+06   \n",
       "25                4.774955e+06              3.751563e+06   \n",
       "26                4.323507e+06              3.396872e+06   \n",
       "27                3.914742e+06              3.075715e+06   \n",
       "28                3.544623e+06              2.784922e+06   \n",
       "29                3.209497e+06              2.521622e+06   \n",
       "..                         ...                       ...   \n",
       "531               5.624880e-01              7.365388e-02   \n",
       "532               5.624817e-01              7.381722e-02   \n",
       "533               5.623023e-01              7.392066e-02   \n",
       "534               5.621907e-01              7.392944e-02   \n",
       "535               5.621227e-01              7.394193e-02   \n",
       "536               5.616730e-01              7.357218e-02   \n",
       "537               5.616133e-01              7.363118e-02   \n",
       "538               5.615703e-01              7.372491e-02   \n",
       "539               5.613463e-01              7.361773e-02   \n",
       "540               5.611210e-01              7.340459e-02   \n",
       "541               5.610567e-01              7.342808e-02   \n",
       "542               5.609513e-01              7.344376e-02   \n",
       "543               5.609023e-01              7.342074e-02   \n",
       "544               5.606613e-01              7.324163e-02   \n",
       "545               5.608900e-01              7.364124e-02   \n",
       "546               5.608207e-01              7.361660e-02   \n",
       "547               5.606840e-01              7.368200e-02   \n",
       "548               5.606313e-01              7.356806e-02   \n",
       "549               5.605773e-01              7.357573e-02   \n",
       "550               5.605623e-01              7.357351e-02   \n",
       "551               5.604447e-01              7.365093e-02   \n",
       "552               5.603207e-01              7.362665e-02   \n",
       "553               5.599213e-01              7.320639e-02   \n",
       "554               5.598857e-01              7.327042e-02   \n",
       "555               5.596933e-01              7.308288e-02   \n",
       "556               5.596553e-01              7.310459e-02   \n",
       "557               5.595150e-01              7.297383e-02   \n",
       "558               5.594050e-01              7.289210e-02   \n",
       "559               5.590237e-01              7.235586e-02   \n",
       "560               5.587077e-01              7.197753e-02   \n",
       "\n",
       "     train-poisson-nloglik-mean  train-poisson-nloglik-std  \n",
       "0                  3.746034e+07               2.640373e+07  \n",
       "1                  3.391865e+07               2.390739e+07  \n",
       "2                  3.071182e+07               2.164707e+07  \n",
       "3                  2.780817e+07               1.960045e+07  \n",
       "4                  2.517905e+07               1.774733e+07  \n",
       "5                  2.279850e+07               1.606941e+07  \n",
       "6                  2.064302e+07               1.455013e+07  \n",
       "7                  1.869133e+07               1.317449e+07  \n",
       "8                  1.692416e+07               1.192891e+07  \n",
       "9                  1.532407e+07               1.080109e+07  \n",
       "10                 1.387526e+07               9.779905e+06  \n",
       "11                 1.256342e+07               8.855265e+06  \n",
       "12                 1.137561e+07               8.018045e+06  \n",
       "13                 1.030011e+07               7.259981e+06  \n",
       "14                 9.326286e+06               6.573587e+06  \n",
       "15                 8.444533e+06               5.952088e+06  \n",
       "16                 7.646146e+06               5.389348e+06  \n",
       "17                 6.923242e+06               4.879813e+06  \n",
       "18                 6.268685e+06               4.418452e+06  \n",
       "19                 5.676012e+06               4.000710e+06  \n",
       "20                 5.139375e+06               3.622463e+06  \n",
       "21                 4.653473e+06               3.279978e+06  \n",
       "22                 4.213511e+06               2.969873e+06  \n",
       "23                 3.815145e+06               2.689087e+06  \n",
       "24                 3.454443e+06               2.434847e+06  \n",
       "25                 3.127842e+06               2.204645e+06  \n",
       "26                 2.832121e+06               1.996207e+06  \n",
       "27                 2.564358e+06               1.807476e+06  \n",
       "28                 2.321911e+06               1.636588e+06  \n",
       "29                 2.102386e+06               1.481857e+06  \n",
       "..                          ...                        ...  \n",
       "531                5.011030e-01               1.744468e-02  \n",
       "532                5.008190e-01               1.718576e-02  \n",
       "533                5.006560e-01               1.723979e-02  \n",
       "534                5.005343e-01               1.724762e-02  \n",
       "535                5.003750e-01               1.716084e-02  \n",
       "536                5.001563e-01               1.705210e-02  \n",
       "537                5.000843e-01               1.704224e-02  \n",
       "538                4.999247e-01               1.700401e-02  \n",
       "539                4.997507e-01               1.688695e-02  \n",
       "540                4.996430e-01               1.688866e-02  \n",
       "541                4.995763e-01               1.688297e-02  \n",
       "542                4.994387e-01               1.693046e-02  \n",
       "543                4.991917e-01               1.709854e-02  \n",
       "544                4.990880e-01               1.710685e-02  \n",
       "545                4.988363e-01               1.710614e-02  \n",
       "546                4.987203e-01               1.710568e-02  \n",
       "547                4.986163e-01               1.715112e-02  \n",
       "548                4.984620e-01               1.715163e-02  \n",
       "549                4.983637e-01               1.711110e-02  \n",
       "550                4.982877e-01               1.712240e-02  \n",
       "551                4.981243e-01               1.719623e-02  \n",
       "552                4.980277e-01               1.718641e-02  \n",
       "553                4.979503e-01               1.718968e-02  \n",
       "554                4.978850e-01               1.720929e-02  \n",
       "555                4.978277e-01               1.719675e-02  \n",
       "556                4.976780e-01               1.707933e-02  \n",
       "557                4.975470e-01               1.695250e-02  \n",
       "558                4.974800e-01               1.688523e-02  \n",
       "559                4.973800e-01               1.675872e-02  \n",
       "560                4.972290e-01               1.665618e-02  \n",
       "\n",
       "[561 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.cv(params=param, dtrain=dtrain, num_boost_round=2000, early_stopping_rounds=10, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-poisson-nloglik:3.74603e+07+2.64037e+07\ttest-poisson-nloglik:4.28139e+07+3.01937e+07\n",
      "[50]\ttrain-poisson-nloglik:261166+184082\ttest-poisson-nloglik:398696+313246\n",
      "[100]\ttrain-poisson-nloglik:1820.39+1283.24\ttest-poisson-nloglik:2779.34+2183.62\n",
      "[150]\ttrain-poisson-nloglik:13.0037+8.66658\ttest-poisson-nloglik:19.701+15.0637\n",
      "[200]\ttrain-poisson-nloglik:0.764747+0.147234\ttest-poisson-nloglik:0.95053+0.368252\n",
      "[250]\ttrain-poisson-nloglik:0.65426+0.116838\ttest-poisson-nloglik:0.790589+0.280088\n",
      "[300]\ttrain-poisson-nloglik:0.589547+0.070015\ttest-poisson-nloglik:0.687559+0.180865\n",
      "[350]\ttrain-poisson-nloglik:0.550226+0.0414191\ttest-poisson-nloglik:0.629144+0.125205\n",
      "[400]\ttrain-poisson-nloglik:0.526795+0.0267183\ttest-poisson-nloglik:0.592965+0.0903845\n",
      "[450]\ttrain-poisson-nloglik:0.514233+0.0230298\ttest-poisson-nloglik:0.576708+0.081113\n",
      "[500]\ttrain-poisson-nloglik:0.506068+0.0199514\ttest-poisson-nloglik:0.566862+0.075905\n",
      "[550]\ttrain-poisson-nloglik:0.498288+0.0171224\ttest-poisson-nloglik:0.560562+0.0735735\n"
     ]
    }
   ],
   "source": [
    "xgb_cv = xgb.cv(params=param, dtrain=dtrain, num_boost_round=2000, early_stopping_rounds=10, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xgb_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = datasets.load_iris().data[:, :2]\n",
    "# y = datasets.load_iris().target\n",
    "# xgb_model = xgb.XGBRegressor()\n",
    "# y_pred = cvp(xgb_model, X, y, cv=3, n_jobs = 1)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst2 = xgb.XGBRegressor(\n",
    "    eta = 0.2,\n",
    "    eval_metric = 'poisson-nloglik',\n",
    "    max_depth = 2,\n",
    "    objective = 'count:poisson',\n",
    "    silent = True,\n",
    "    verbose_eval = 10,\n",
    "    early_stopping_rounds=50,\n",
    "    num_round = 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00691906,  0.23277925,  0.08715432, ...,  0.17767455,\n",
       "        0.22702384,  0.52751034], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cvp(bst2, X, y, cv=5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323080807398694.56"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO why is this mse so much bigger?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wout/.local/lib/python3.5/site-packages/ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "/home/wout/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/wout/.local/lib/python3.5/site-packages/ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-45d6f9d515bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_keras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_keras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# generate regression dataset\n",
    "# X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=1)\n",
    "scalarX, scalarY = MinMaxScaler(), MinMaxScaler()\n",
    "scalarX.fit(X_train)\n",
    "scalarY.fit(y_train.reshape(len(y_train),1))\n",
    "X_keras = scalarX.transform(X_train)\n",
    "y_keras = scalarY.transform(y_train.reshape(len(y_train),1))\n",
    "# define and fit the final model\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=7, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_keras, y_keras, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new instances where we do not know the answer\n",
    "X_keras_test = scalarX.transform(X_test)\n",
    "# make a prediction\n",
    "y_pred_keras = model.predict(X_keras_test)# show the inputs and predicted outputs\n",
    "\n",
    "mean_squared_error(np.hstack(y_pred_keras), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_comparison = pd.DataFrame({\n",
    "    'y_test': y_test,\n",
    "    'y_pred_keras': np.hstack(y_pred_keras)\n",
    "})\n",
    "\n",
    "keras_comparison.groupby('y_test').agg({\n",
    "    'y_pred_keras': [np.min, np.mean, np.median, np.max]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_in_xgboost_package(params, dtrain, num_boost_round=10, nfold=3, stratified=False, folds=None,\n",
    "       metrics=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None,\n",
    "       fpreproc=None, as_pandas=True, verbose_eval=None, show_stdv=True,\n",
    "       seed=0, callbacks=None, shuffle=True):\n",
    "    # pylint: disable = invalid-name\n",
    "    \"\"\"Cross-validation with given parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : dict\n",
    "        Booster params.\n",
    "    dtrain : DMatrix\n",
    "        Data to be trained.\n",
    "    num_boost_round : int\n",
    "        Number of boosting iterations.\n",
    "    nfold : int\n",
    "        Number of folds in CV.\n",
    "    stratified : bool\n",
    "        Perform stratified sampling.\n",
    "    folds : a KFold or StratifiedKFold instance or list of fold indices\n",
    "        Sklearn KFolds or StratifiedKFolds object.\n",
    "        Alternatively may explicitly pass sample indices for each fold.\n",
    "        For `n` folds, `folds` should be a length `n` list of tuples.\n",
    "        Each tuple is `(in,out)` where `in` is a list of indices to be used\n",
    "        as the training samples for the `n`th fold and `out` is a list of\n",
    "        indices to be used as the testing samples for the `n`th fold.\n",
    "    metrics : string or list of strings\n",
    "        Evaluation metrics to be watched in CV.\n",
    "    obj : function\n",
    "        Custom objective function.\n",
    "    feval : function\n",
    "        Custom evaluation function.\n",
    "    maximize : bool\n",
    "        Whether to maximize feval.\n",
    "    early_stopping_rounds: int\n",
    "        Activates early stopping. CV error needs to decrease at least\n",
    "        every <early_stopping_rounds> round(s) to continue.\n",
    "        Last entry in evaluation history is the one from best iteration.\n",
    "    fpreproc : function\n",
    "        Preprocessing function that takes (dtrain, dtest, param) and returns\n",
    "        transformed versions of those.\n",
    "    as_pandas : bool, default True\n",
    "        Return pd.DataFrame when pandas is installed.\n",
    "        If False or pandas is not installed, return np.ndarray\n",
    "    verbose_eval : bool, int, or None, default None\n",
    "        Whether to display the progress. If None, progress will be displayed\n",
    "        when np.ndarray is returned. If True, progress will be displayed at\n",
    "        boosting stage. If an integer is given, progress will be displayed\n",
    "        at every given `verbose_eval` boosting stage.\n",
    "    show_stdv : bool, default True\n",
    "        Whether to display the standard deviation in progress.\n",
    "        Results are not affected, and always contains std.\n",
    "    seed : int\n",
    "        Seed used to generate the folds (passed to numpy.random.seed).\n",
    "    callbacks : list of callback functions\n",
    "        List of callback functions that are applied at end of each iteration.\n",
    "        It is possible to use predefined callbacks by using xgb.callback module.\n",
    "        Example: [xgb.callback.reset_learning_rate(custom_rates)]\n",
    "     shuffle : bool\n",
    "        Shuffle data before creating folds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    evaluation history : list(string)\n",
    "    \"\"\"\n",
    "    if stratified is True and not SKLEARN_INSTALLED:\n",
    "        raise XGBoostError('sklearn needs to be installed in order to use stratified cv')\n",
    "\n",
    "    if isinstance(metrics, str):\n",
    "        metrics = [metrics]\n",
    "\n",
    "    if isinstance(params, list):\n",
    "        _metrics = [x[1] for x in params if x[0] == 'eval_metric']\n",
    "        params = dict(params)\n",
    "        if 'eval_metric' in params:\n",
    "            params['eval_metric'] = _metrics\n",
    "    else:\n",
    "        params = dict((k, v) for k, v in params.items())\n",
    "\n",
    "    if len(metrics) == 0 and 'eval_metric' in params:\n",
    "        if isinstance(params['eval_metric'], list):\n",
    "            metrics = params['eval_metric']\n",
    "        else:\n",
    "            metrics = [params['eval_metric']]\n",
    "\n",
    "    params.pop(\"eval_metric\", None)\n",
    "\n",
    "    results = {}\n",
    "    cvfolds = mknfold(dtrain, nfold, params, seed, metrics, fpreproc,\n",
    "                      stratified, folds, shuffle)\n",
    "\n",
    "    # setup callbacks\n",
    "    callbacks = [] if callbacks is None else callbacks\n",
    "    if early_stopping_rounds is not None:\n",
    "        callbacks.append(callback.early_stop(early_stopping_rounds,\n",
    "                                             maximize=maximize,\n",
    "                                             verbose=False))\n",
    "\n",
    "    if isinstance(verbose_eval, bool) and verbose_eval:\n",
    "        callbacks.append(callback.print_evaluation(show_stdv=show_stdv))\n",
    "    else:\n",
    "        if isinstance(verbose_eval, int):\n",
    "            callbacks.append(callback.print_evaluation(verbose_eval, show_stdv=show_stdv))\n",
    "\n",
    "    callbacks_before_iter = [\n",
    "        cb for cb in callbacks if cb.__dict__.get('before_iteration', False)]\n",
    "    callbacks_after_iter = [\n",
    "        cb for cb in callbacks if not cb.__dict__.get('before_iteration', False)]\n",
    "\n",
    "    for i in range(num_boost_round):\n",
    "        for cb in callbacks_before_iter:\n",
    "            cb(CallbackEnv(model=None,\n",
    "                           cvfolds=cvfolds,\n",
    "                           iteration=i,\n",
    "                           begin_iteration=0,\n",
    "                           end_iteration=num_boost_round,\n",
    "                           rank=0,\n",
    "                           evaluation_result_list=None))\n",
    "        for fold in cvfolds:\n",
    "            fold.update(i, obj)\n",
    "        res = aggcv([f.eval(i, feval) for f in cvfolds])\n",
    "\n",
    "        for key, mean, std in res:\n",
    "            if key + '-mean' not in results:\n",
    "                results[key + '-mean'] = []\n",
    "            if key + '-std' not in results:\n",
    "                results[key + '-std'] = []\n",
    "            results[key + '-mean'].append(mean)\n",
    "            results[key + '-std'].append(std)\n",
    "        try:\n",
    "            for cb in callbacks_after_iter:\n",
    "                cb(CallbackEnv(model=None,\n",
    "                               cvfolds=cvfolds,\n",
    "                               iteration=i,\n",
    "                               begin_iteration=0,\n",
    "                               end_iteration=num_boost_round,\n",
    "                               rank=0,\n",
    "                               evaluation_result_list=res))\n",
    "        except EarlyStopException as e:\n",
    "            for k in results.keys():\n",
    "                results[k] = results[k][:(e.best_iteration + 1)]\n",
    "            break\n",
    "    if as_pandas:\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            results = pd.DataFrame.from_dict(results)\n",
    "        except ImportError:\n",
    "            pass\n",
    "    return results\n",
    "\n",
    "\n",
    "def cv_pete(D_cv_in, D_cv_out, params, num_boost_round, early_stopping_rounds=None,\n",
    "       metrics=None, obj=None, feval=None, maximize=False, callbacks=None,\n",
    "       verbose_eval=False, show_stdv=False, as_pandas=True):\n",
    "    \"\"\"\n",
    "    Custom xgboost cross-validation function which uses pre-computed in/out of\n",
    "    fold design matrices and returns the fold-wise models so that they can be used\n",
    "    for prediction and further analysis.\n",
    "    The function is based on the default cv() in:\n",
    "    https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/training.py\n",
    "    This differs to the default xgboost.cv function in the following key ways:\n",
    "        - cv fold design matrices can be pre-computed to avoid repeating this time\n",
    "          consuming step every time cv() is called\n",
    "        - the CVPack objects are returned (which include the boosters for each\n",
    "          fold), allowing the cross-validated models to be used for prediction\n",
    "        - cv fold creation functionality dropped (as they should be pre-computed)\n",
    "    Parameters different to default function:\n",
    "    :param D_cv_in: list of 'in-fold' design matrices, to be used for training\n",
    "    :type D_cv_in: list[DMatrix]\n",
    "    :param D_cv_out: list of 'out-of-fold' design matrices, to be used for evaluation\n",
    "    :type D_cv_out: list[DMatrix]\n",
    "    :param dict params: Booster params.\n",
    "    :param int num_boost_round: Number of boosting iterations.\n",
    "    :param metrics: Evaluation metrics to be watched in CV.\n",
    "    :type metrics: str or list[str]\n",
    "    :param func obj: Custom objective function.\n",
    "    :param func feval: Custom evaluation function.\n",
    "    :param bools maximize: Whether to maximize feval.\n",
    "    :param int early_stopping_rounds: Activates early stopping. CV error needs to decrease at least\n",
    "        every <early_stopping_rounds> round(s) to continue. Last entry in evaluation history is\n",
    "        the one from best iteration.\n",
    "    :param bool as_pandas: default True. Return pd.DataFrame when pandas is installed.\n",
    "        If False or pandas is not installed, return np.ndarray\n",
    "    :param bool verbose_eval: Default None.\n",
    "        Whether to display the progress. If None, progress will be displayed\n",
    "        when np.ndarray is returned. If True, progress will be displayed at\n",
    "        boosting stage. If an integer is given, progress will be displayed\n",
    "        at every given `verbose_eval` boosting stage.\n",
    "    :type verbose_eval: bool, int, or None\n",
    "    :param boolt show_stdv : default True.\n",
    "        Whether to display the standard deviation in progress.\n",
    "        Results are not affected, and always contains std.\n",
    "    :param callbacks: List of callback functions that are applied at end of each iteration.\n",
    "        It is possible to use predefined callbacks by using xgb.callback module.\n",
    "        Example: [xgb.callback.reset_learning_rate(custom_rates)]\n",
    "    :type callbacks: list[func]\n",
    "    :returns model_cv: collection of in/out-of-fold design matrices, parameters and\n",
    "        trained boosters for each fold\n",
    "    :rtype model_cv: xgboost.training.CVPack\n",
    "    :returns results: cross-validation and training errors by iteration\n",
    "    :rtype results: pd.DataFrame (if as_pandas=True) or dict\n",
    "    \"\"\"\n",
    "\n",
    "    # Clean parameters\n",
    "    if isinstance(metrics, str):\n",
    "        metrics = [metrics]\n",
    "\n",
    "    if isinstance(params, list):\n",
    "        _metrics = [x[1] for x in params if x[0] == 'eval_metric']\n",
    "        params = dict(params)\n",
    "        if 'eval_metric' in params:\n",
    "            params['eval_metric'] = _metrics\n",
    "    else:\n",
    "        params = dict((k, v) for k, v in params.items())\n",
    "\n",
    "    if metrics is None and 'eval_metric' in params:\n",
    "        if isinstance(params['eval_metric'], list):\n",
    "            metrics = params['eval_metric']\n",
    "        else:\n",
    "            metrics = [params['eval_metric']]\n",
    "\n",
    "    params.pop(\"eval_metric\", None)\n",
    "\n",
    "    params = list(params.items()) + [('eval_metric', itm) for itm in metrics]\n",
    "\n",
    "    # initialise models and results\n",
    "    nfold = len(D_cv_in)\n",
    "    results = {}\n",
    "    model_cv = [CVPack(dtest=D_cv_out[k], dtrain=D_cv_in[k], param=params) for k in range(nfold)]\n",
    "\n",
    "    # Setup callbacks\n",
    "    callbacks = [] if callbacks is None else callbacks\n",
    "    if early_stopping_rounds is not None:\n",
    "        callbacks.append(callback.early_stop(early_stopping_rounds,\n",
    "                                             maximize=maximize,\n",
    "                                             verbose=True))\n",
    "    if isinstance(verbose_eval, bool) and verbose_eval:\n",
    "        callbacks.append(callback.print_evaluation(show_stdv=show_stdv))\n",
    "    else:\n",
    "        if isinstance(verbose_eval, int):\n",
    "            callbacks.append(callback.print_evaluation(verbose_eval,\n",
    "                                                       show_stdv=show_stdv))\n",
    "\n",
    "    callbacks_before_iter = [\n",
    "        cb for cb in callbacks if cb.__dict__.get('before_iteration', False)\n",
    "    ]\n",
    "    callbacks_after_iter = [\n",
    "        cb for cb in callbacks if not cb.__dict__.get('before_iteration', False)\n",
    "    ]\n",
    "\n",
    "    for i in range(num_boost_round):\n",
    "        for cb in callbacks_before_iter:\n",
    "            cb(CallbackEnv(model=None,\n",
    "                           cvfolds=model_cv,\n",
    "                           iteration=i,\n",
    "                           begin_iteration=0,\n",
    "                           end_iteration=num_boost_round,\n",
    "                           rank=0,\n",
    "                           evaluation_result_list=None))\n",
    "        for fold in model_cv:\n",
    "            fold.update(i, obj)\n",
    "        res = aggcv([f.eval(i, feval) for f in model_cv])\n",
    "\n",
    "        for key, mean, std in res:\n",
    "            if key + '-mean' not in results:\n",
    "                results[key + '-mean'] = []\n",
    "            if key + '-std' not in results:\n",
    "                results[key + '-std'] = []\n",
    "            results[key + '-mean'].append(mean)\n",
    "            results[key + '-std'].append(std)\n",
    "        try:\n",
    "            for cb in callbacks_after_iter:\n",
    "                cb(CallbackEnv(model=None,\n",
    "                               cvfolds=model_cv,\n",
    "                               iteration=i,\n",
    "                               begin_iteration=0,\n",
    "                               end_iteration=num_boost_round,\n",
    "                               rank=0,\n",
    "                               evaluation_result_list=res))\n",
    "        except EarlyStopException as e:\n",
    "            for k in results.keys():\n",
    "                results[k] = results[k][:(e.best_iteration + 1)]\n",
    "            break\n",
    "    if as_pandas:\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            results = pd.DataFrame.from_dict(results)\n",
    "        except ImportError:\n",
    "            pass\n",
    "    return model_cv, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_diff = '''    if stratified is True and not SKLEARN_INSTALLED:\n",
    "        raise XGBoostError('sklearn needs to be installed in order to use stratified cv')\n",
    " '''\n",
    "\n",
    "same_stuff_str = '''\n",
    "    if isinstance(metrics, str):\n",
    "        metrics = [metrics]\n",
    "\n",
    "    if isinstance(params, list):\n",
    "        _metrics = [x[1] for x in params if x[0] == 'eval_metric']\n",
    "        params = dict(params)\n",
    "        if 'eval_metric' in params:\n",
    "            params['eval_metric'] = _metrics\n",
    "    else:\n",
    "        params = dict((k, v) for k, v in params.items())\n",
    "\n",
    "    if metrics is None and 'eval_metric' in params: # only this changed from if len(metric) == 0 \n",
    "        if isinstance(params['eval_metric'], list):\n",
    "            metrics = params['eval_metric']\n",
    "        else:\n",
    "            metrics = [params['eval_metric']]\n",
    "\n",
    "    params.pop(\"eval_metric\", None)\n",
    "\n",
    "'''\n",
    "\n",
    "pete_added_this == '''    params = list(params.items()) + [('eval_metric', itm) for itm in metrics]\n",
    "'''\n",
    "\n",
    "cv_in_xgboost_package_string = \n",
    "\n",
    "\n",
    "    results = {}\n",
    "    cvfolds = mknfold(dtrain, nfold, params, seed, metrics, fpreproc,\n",
    "                      stratified, folds, shuffle)\n",
    "\n",
    "    # setup callbacks\n",
    "    callbacks = [] if callbacks is None else callbacks\n",
    "    if early_stopping_rounds is not None:\n",
    "        callbacks.append(callback.early_stop(early_stopping_rounds,\n",
    "                                             maximize=maximize,\n",
    "                                             verbose=False))\n",
    "\n",
    "    if isinstance(verbose_eval, bool) and verbose_eval:\n",
    "        callbacks.append(callback.print_evaluation(show_stdv=show_stdv))\n",
    "    else:\n",
    "        if isinstance(verbose_eval, int):\n",
    "            callbacks.append(callback.print_evaluation(verbose_eval, show_stdv=show_stdv))\n",
    "\n",
    "    callbacks_before_iter = [\n",
    "        cb for cb in callbacks if cb.__dict__.get('before_iteration', False)]\n",
    "    callbacks_after_iter = [\n",
    "        cb for cb in callbacks if not cb.__dict__.get('before_iteration', False)]\n",
    "\n",
    "    for i in range(num_boost_round):\n",
    "        for cb in callbacks_before_iter:\n",
    "            cb(CallbackEnv(model=None,\n",
    "                           cvfolds=cvfolds,\n",
    "                           iteration=i,\n",
    "                           begin_iteration=0,\n",
    "                           end_iteration=num_boost_round,\n",
    "                           rank=0,\n",
    "                           evaluation_result_list=None))\n",
    "        for fold in cvfolds:\n",
    "            fold.update(i, obj)\n",
    "        res = aggcv([f.eval(i, feval) for f in cvfolds])\n",
    "\n",
    "        for key, mean, std in res:\n",
    "            if key + '-mean' not in results:\n",
    "                results[key + '-mean'] = []\n",
    "            if key + '-std' not in results:\n",
    "                results[key + '-std'] = []\n",
    "            results[key + '-mean'].append(mean)\n",
    "            results[key + '-std'].append(std)\n",
    "        try:\n",
    "            for cb in callbacks_after_iter:\n",
    "                cb(CallbackEnv(model=None,\n",
    "                               cvfolds=cvfolds,\n",
    "                               iteration=i,\n",
    "                               begin_iteration=0,\n",
    "                               end_iteration=num_boost_round,\n",
    "                               rank=0,\n",
    "                               evaluation_result_list=res))\n",
    "        except EarlyStopException as e:\n",
    "            for k in results.keys():\n",
    "                results[k] = results[k][:(e.best_iteration + 1)]\n",
    "            break\n",
    "    if as_pandas:\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            results = pd.DataFrame.from_dict(results)\n",
    "        except ImportError:\n",
    "            pass\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "cv_pete_string = \n",
    "\n",
    "\n",
    "   # initialise models and results\n",
    "    nfold = len(D_cv_in) #### pete adddes this\n",
    "    results = {}\n",
    "    model_cv = [CVPack(dtest=D_cv_out[k], dtrain=D_cv_in[k], param=params) for k in range(nfold)] #### pete adds this but this is copied from the package \n",
    "\n",
    "    # Setup callbacks\n",
    "    callbacks = [] if callbacks is None else callbacks\n",
    "    if early_stopping_rounds is not None:\n",
    "        callbacks.append(callback.early_stop(early_stopping_rounds,\n",
    "                                             maximize=maximize,\n",
    "                                             verbose=True))\n",
    "    if isinstance(verbose_eval, bool) and verbose_eval:\n",
    "        callbacks.append(callback.print_evaluation(show_stdv=show_stdv))\n",
    "    else:\n",
    "        if isinstance(verbose_eval, int):\n",
    "            callbacks.append(callback.print_evaluation(verbose_eval,\n",
    "                                                       show_stdv=show_stdv))\n",
    "\n",
    "    callbacks_before_iter = [\n",
    "        cb for cb in callbacks if cb.__dict__.get('before_iteration', False)\n",
    "    ]\n",
    "    callbacks_after_iter = [\n",
    "        cb for cb in callbacks if not cb.__dict__.get('before_iteration', False)\n",
    "    ]\n",
    "\n",
    "    for i in range(num_boost_round):\n",
    "        for cb in callbacks_before_iter:\n",
    "            cb(CallbackEnv(model=None,\n",
    "                           cvfolds=model_cv,\n",
    "                           iteration=i,\n",
    "                           begin_iteration=0,\n",
    "                           end_iteration=num_boost_round,\n",
    "                           rank=0,\n",
    "                           evaluation_result_list=None))\n",
    "        for fold in model_cv:\n",
    "            fold.update(i, obj)\n",
    "        res = aggcv([f.eval(i, feval) for f in model_cv])\n",
    "\n",
    "        for key, mean, std in res:\n",
    "            if key + '-mean' not in results:\n",
    "                results[key + '-mean'] = []\n",
    "            if key + '-std' not in results:\n",
    "                results[key + '-std'] = []\n",
    "            results[key + '-mean'].append(mean)\n",
    "            results[key + '-std'].append(std)\n",
    "        try:\n",
    "            for cb in callbacks_after_iter:\n",
    "                cb(CallbackEnv(model=None,\n",
    "                               cvfolds=model_cv,\n",
    "                               iteration=i,\n",
    "                               begin_iteration=0,\n",
    "                               end_iteration=num_boost_round,\n",
    "                               rank=0,\n",
    "                               evaluation_result_list=res))\n",
    "        except EarlyStopException as e:\n",
    "            for k in results.keys():\n",
    "                results[k] = results[k][:(e.best_iteration + 1)]\n",
    "            break\n",
    "    if as_pandas:\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            results = pd.DataFrame.from_dict(results)\n",
    "        except ImportError:\n",
    "            pass\n",
    "    return model_cv, results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
